import streamlit as st
import pandas as pd
from io import BytesIO
from thefuzz import fuzz
from docx import Document

# Matnni normallashtirish funksiyasi
def normalize_text(s):
    if pd.isna(s):
        return ""
    s = str(s).strip().lower()
    s = s.replace("â€™", "'").replace("â€˜", "'").replace("`", "'")
    s = s.replace("o'", "oâ€˜").replace("g'", "gâ€˜")
    s = " ".join(s.split())
    return s

# Word faylini o'qish (matn yoki jadval)
def read_doc_or_docx(file):
    file_bytes = file.read()
    file.seek(0)
    doc = Document(BytesIO(file_bytes))

    if doc.tables:
        tables_data = []
        for table in doc.tables:
            for row in table.rows:
                row_data = [cell.text.strip() for cell in row.cells]
                tables_data.append(row_data)
        df = pd.DataFrame(tables_data)
        df.columns = df.iloc[0]
        df = df[1:].reset_index(drop=True)
        return df

    full_text = [para.text.strip() for para in doc.paragraphs if para.text.strip()]
    return pd.DataFrame(full_text, columns=["Data"])

# Fayl yuklash va DataFrame ga o'qish funksiyasi
def load_file(file):
    if file.name.endswith(".xlsx"):
        return pd.read_excel(file)
    elif file.name.endswith(".csv"):
        return pd.read_csv(file)
    elif file.name.endswith(".doc") or file.name.endswith(".docx"):
        return read_doc_or_docx(file)
    elif file.name.endswith(".txt"):
        text = file.read().decode("utf-8")
        lines = [line.strip() for line in text.splitlines() if line.strip()]
        return pd.DataFrame(lines, columns=["Data"])
    else:
        st.error(texts["unsupported_format"][current_lang])
        return None

# Til uchun lug'at
texts = {
    "title": {
        "uz": "ðŸ“Š Ma'lumotlarni Taqqoslash Platformasi (Demo)",
        "ru": "ðŸ“Š ÐŸÐ»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð° ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… (Ð”ÐµÐ¼Ð¾)",
        "en": "ðŸ“Š Data Comparison Platform (Demo)"
    },
    "upload_db": {
        "uz": "1ï¸âƒ£ Ma'lumotlar bazasini yuklang (.xlsx, .csv, .doc, .docx, .txt)",
        "ru": "1ï¸âƒ£ Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ… (.xlsx, .csv, .doc, .docx, .txt)",
        "en": "1ï¸âƒ£ Upload database (.xlsx, .csv, .doc, .docx, .txt)"
    },
    "upload_check": {
        "uz": "2ï¸âƒ£ Tekshiriladigan ma'lumotlarni yuklang yoki kiriting",
        "ru": "2ï¸âƒ£ Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð¸Ð»Ð¸ Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ",
        "en": "2ï¸âƒ£ Upload or enter data to check"
    },
    "input_method": {
        "uz": "Kiritish usuli",
        "ru": "Ð¡Ð¿Ð¾ÑÐ¾Ð± Ð²Ð²Ð¾Ð´Ð°",
        "en": "Input method"
    },
    "file_upload": {
        "uz": "Fayl yuklash",
        "ru": "Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ„Ð°Ð¹Ð»Ð°",
        "en": "File upload"
    },
    "manual_input": {
        "uz": "Qo'lda kiritish",
        "ru": "Ð ÑƒÑ‡Ð½Ð¾Ð¹ Ð²Ð²Ð¾Ð´",
        "en": "Manual input"
    },
    "input_placeholder": {
        "uz": "Ma'lumotlarni kiriting (vergul yoki yangi qatordan ajratib)",
        "ru": "Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ (Ñ‡ÐµÑ€ÐµÐ· Ð·Ð°Ð¿ÑÑ‚ÑƒÑŽ Ð¸Ð»Ð¸ Ñ Ð½Ð¾Ð²Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐ¸)",
        "en": "Enter data (comma or newline separated)"
    },
    "choose_db_column": {
        "uz": "Bazadagi taqqoslanadigan ustunni tanlang",
        "ru": "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÑ‚Ð¾Ð»Ð±ÐµÑ† Ð´Ð»Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ Ð² Ð±Ð°Ð·Ðµ",
        "en": "Select database column to compare"
    },
    "choose_input_column": {
        "uz": "Tekshiriladigan fayldagi ustunni tanlang",
        "ru": "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÑ‚Ð¾Ð»Ð±ÐµÑ† Ð¸Ð· Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð°",
        "en": "Select input file column"
    },
    "extra_columns": {
        "uz": "Natijada ko'rsatish uchun qo'shimcha ustunlar",
        "ru": "Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹ Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ",
        "en": "Additional columns to show in results"
    },
    "similarity_threshold": {
        "uz": "O'xshashlik minimal balli",
        "ru": "ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³ Ð¿Ð¾Ñ…Ð¾Ð¶ÐµÑÑ‚Ð¸",
        "en": "Similarity threshold"
    },
    "compare_button": {
        "uz": "Taqqoslash",
        "ru": "Ð¡Ñ€Ð°Ð²Ð½Ð¸Ñ‚ÑŒ",
        "en": "Compare"
    },
    "results_title": {
        "uz": "Natijalar",
        "ru": "Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹",
        "en": "Results"
    },
    "download_csv": {
        "uz": "ðŸ“¥ Natijani yuklab olish (.csv)",
        "ru": "ðŸ“¥ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (.csv)",
        "en": "ðŸ“¥ Download results (.csv)"
    },
    "match_yes": {
        "uz": "Ha",
        "ru": "Ð”Ð°",
        "en": "Yes"
    },
    "match_no": {
        "uz": "Yo'q",
        "ru": "ÐÐµÑ‚",
        "en": "No"
    },
    "unsupported_format": {
        "uz": "Qo'llab-quvvatlanmaydigan format",
        "ru": "ÐÐµÐ¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚",
        "en": "Unsupported format"
    }
}

# Tilni tanlash
lang_options = {"Oâ€˜zbekcha": "uz", "Ð ÑƒÑÑÐºÐ¸Ð¹": "ru", "English": "en"}
selected_lang = st.selectbox("Tilni tanlang / Select language / Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÐ·Ñ‹Ðº", list(lang_options.keys()))
current_lang = lang_options[selected_lang]

# Streamlit interfeysini tanlangan tilga mos chiqarish
st.title(texts["title"][current_lang])

st.subheader(texts["upload_db"][current_lang])
uploaded_db = st.file_uploader("", type=["xlsx", "csv", "doc", "docx", "txt"])

st.subheader(texts["upload_check"][current_lang])
input_type = st.radio(texts["input_method"][current_lang], [texts["file_upload"][current_lang], texts["manual_input"][current_lang]])

input_data = None
if input_type == texts["file_upload"][current_lang]:
    uploaded_check = st.file_uploader("", type=["xlsx", "csv", "doc", "docx", "txt"])
    if uploaded_check is not None:
        input_data = load_file(uploaded_check)
elif input_type == texts["manual_input"][current_lang]:
    raw_text = st.text_area(texts["input_placeholder"][current_lang])
    if raw_text.strip():
        items = [x.strip() for x in raw_text.replace("\n", ",").split(",") if x.strip()]
        input_data = pd.DataFrame(items, columns=["InputData"])

similarity_threshold = st.slider(texts["similarity_threshold"][current_lang], min_value=50, max_value=100, value=80, step=1)

if uploaded_db is not None:
    df = load_file(uploaded_db)

    if df is not None:
        st.write(f"**{texts['upload_db'][current_lang]}**")
        st.dataframe(df)

        if input_data is not None:
            st.write(f"**{texts['upload_check'][current_lang]}**")
            st.dataframe(input_data)

            column_to_check = st.selectbox(texts["choose_db_column"][current_lang], df.columns)
            input_column_to_check = st.selectbox(texts["choose_input_column"][current_lang], input_data.columns)

            extra_columns = st.multiselect(texts["extra_columns"][current_lang],
                                           [col for col in df.columns if col != column_to_check])

            if st.button(texts["compare_button"][current_lang]):
                df["__norm_col__"] = df[column_to_check].apply(normalize_text)
                input_data["__norm_input__"] = input_data[input_column_to_check].apply(normalize_text)

                results = []
                for item in input_data["__norm_input__"]:
                    exact_match = item in df["__norm_col__"].values
                    match_rows = df[df["__norm_col__"] == item] if exact_match else pd.DataFrame()

                    similar_items = []
                    for val in df["__norm_col__"].unique():
                        if fuzz.ratio(item, val) >= similarity_threshold and val != item:
                            similar_items.append(val)

                    extra_data = {}
                    for col in extra_columns:
                        if not match_rows.empty:
                            extra_data[col] = ", ".join(match_rows[col].astype(str).unique())
                        else:
                            extra_data[col] = ""

                    results.append({
                        "Kiritilgan": item,
                        "Mavjud": texts["match_yes"][current_lang] if exact_match else texts["match_no"][current_lang],
                        "O'xshashlar": ", ".join(similar_items) if similar_items else "-",
                        **extra_data
                    })

                result_df = pd.DataFrame(results)
                st.subheader(texts["results_title"][current_lang])
                st.dataframe(result_df)

                csv = result_df.to_csv(index=False).encode('utf-8')
                st.download_button(texts["download_csv"][current_lang], csv, "natijalar.csv", "text/csv")
